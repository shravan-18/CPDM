!!python/object:argparse.Namespace
args: !!python/object:argparse.Namespace
  config: .\configs\Template-CPDM.yaml
  gpu_ids: '0'
  max_epoch: null
  max_steps: null
  port: '12355'
  result_path: results
  resume_model: null
  resume_optim: null
  sample_at_start: false
  sample_to_eval: false
  save_top: false
  seed: 1234
  train: false
data: !!python/object:argparse.Namespace
  dataset_config: !!python/object:argparse.Namespace
    channels: 1
    dataset_path: E:\Nagasaki Internship\Diffusion\data\preprocessed_data_png
    flip: false
    image_size: 256
    max_pixel_cond: 1
    max_pixel_ori: 1
    to_normal: true
  dataset_name: CT2PET_translation
  dataset_type: custom_aligned
  test: !!python/object:argparse.Namespace
    batch_size: 16
  train: !!python/object:argparse.Namespace
    batch_size: 16
    shuffle: true
  val: !!python/object:argparse.Namespace
    batch_size: 16
    shuffle: true
model: !!python/object:argparse.Namespace
  BB: !!python/object:argparse.Namespace
    lr_scheduler: !!python/object:argparse.Namespace
      cooldown: 3000
      factor: 0.5
      min_lr: 5.0e-07
      patience: 3000
      threshold: 0.0001
    optimizer: !!python/object:argparse.Namespace
      beta1: 0.9
      lr: 0.0001
      optimizer: Adam
      weight_decay: 0.0
    params: !!python/object:argparse.Namespace
      UNetParams: !!python/object:argparse.Namespace
        attention_resolutions: !!python/tuple
        - 32
        - 16
        - 8
        channel_mult: !!python/tuple
        - 1
        - 2
        - 3
        - 4
        condition_key: SpatialRescaler
        context_dim: null
        conv_resample: true
        dims: 2
        image_size: 64
        in_channels: 9
        model_channels: 128
        num_head_channels: 64
        num_heads: 8
        num_res_blocks: 2
        out_channels: 3
        resblock_updown: true
        use_scale_shift_norm: true
        use_spatial_transformer: false
      eta: 1.0
      loss_type: l1
      max_var: 1.0
      mt_type: linear
      num_timesteps: 1000
      objective: grad
      sample_step: 200
      sample_type: linear
      skip_sample: true
  CondStageParams: !!python/object:argparse.Namespace
    in_channels: 1
    n_stages: 2
    out_channels: 3
  EMA: !!python/object:argparse.Namespace
    ema_decay: 0.995
    start_ema_step: 30000
    update_ema_interval: 8
    use_ema: true
  VQGAN: !!python/object:argparse.Namespace
    params: !!python/object:argparse.Namespace
      ckpt_path: E:\Nagasaki Internship\Diffusion\CPDM_VQGAN\last_model.ckpt
      ddconfig: !!python/object:argparse.Namespace
        attn_resolutions: []
        ch: 128
        ch_mult: !!python/tuple
        - 1
        - 2
        - 4
        double_z: false
        dropout: 0.0
        in_channels: 1
        num_res_blocks: 1
        out_ch: 1
        resolution: 256
        z_channels: 3
      embed_dim: 3
      lossconfig: !!python/object:argparse.Namespace
        target: torch.nn.Identity
      n_embed: 8192
  attention_map_train_path: path/to/training/samples/of/segmentor
  attention_map_val_path: path/to/validation-or-testing/samples/of/segmentor
  latent_before_quant_conv: false
  model_name: CPDM
  model_type: CPDM
  normalize_latent: false
  only_load_latent_mean_std: false
result: !!python/object:argparse.Namespace
  ckpt_path: results\CT2PET_translation\CPDM\checkpoint
  image_path: results\CT2PET_translation\CPDM\image
  log_path: results\CT2PET_translation\CPDM\log
  sample_path: results\CT2PET_translation\CPDM\samples
  sample_to_eval_path: results\CT2PET_translation\CPDM\sample_to_eval
runner: CPDMRunner
testing: !!python/object:argparse.Namespace
  clip_denoised: false
  sample_num: 1
training: !!python/object:argparse.Namespace
  accumulate_grad_batches: 4
  device:
  - !!python/object/apply:torch.device
    - cuda
    - 0
  n_epochs: 200
  n_steps: 200000
  sample_interval: 2
  save_interval: 2
  use_DDP: false
  validation_interval: 2
